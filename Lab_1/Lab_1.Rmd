---
title: "Lab 1"
author: "Jordan Garrett"
date: "1/7/2022"
output:
  beamer_presentation: default
  ioslides_presentation:
    transition: faster
classoption: "handout"
---
```{css, echo = FALSE}
.indent {
 margin-left: 30px;
}

h2 {
  font-family: 'Open Sans', sans-serif;
  font-weight: bold;
}

slides > slide {
  color: black;
}
```

```{r setup, include=FALSE}

if (!require(kableExtra)) install.packages('kableExtra')
if (!require(plotly)) install.packages('plotly')

library(knitr)
library(cowplot)
library(tidyverse)
library(MASS)
library(mvtnorm)
library(plotly)
library(kableExtra)

opts_chunk$set(echo = TRUE, warning=F, message=F)
```

## About me {.build}
```{r photos, echo=FALSE}
p1 <- ggdraw() + draw_image('images/bike_eeg.jpeg', scale=1)
p2 <- ggdraw() + draw_image('images/cucomonga.jpeg', scale=0.8)
plot_grid(p1,p2)
```

## Purpose of labs
- Facilitate learning theoretical concepts covered in lecture
- Answer questions about homework
- Review for midterms and the final
- Implement statistical analyses from lecture in RStudio

## Lab 1 Outline
- Cover preliminary statistics and probability concepts
- Intro to R and setup

## Random Variable
> - A variable that takes on specific values with specific probabilities.
> - Measurable functions that map outcomes of a stochastic process to a measurable space.
> - Typically denoted by a capital letter (e.g., *X*, *Y*, *Z*).
> - Denote the outcome of a coin flip as *Y*
>   - *Y* = 1 if Heads, else *Y* = 0
>   - *p*(*Y*=1) = 0.5

## Probability distribution {.build}
- Probability **mass** function (PMF)
   - Assigns probabilities to individual values of a *discrete* random variable
   
```{r coin_plot, echo=FALSE}
data.frame(outcome=c('0','1'), 'p'=c(0.5,0.5)) %>% 
  ggplot(aes(x=outcome, y=p)) + 
  geom_bar(stat='identity', fill='blue', alpha=0.3, color='black') + 
  ylim(0,1) + 
  labs(y=expression(paste(italic(p),'(', italic('Y'),')')), x='', title='Coin Flip PMF') + 
  theme_classic() + 
  theme(plot.title = element_text(hjust=0.5, size = 16),
        axis.text = element_text(size=12), 
        axis.title = element_text(size=14))
```

## Probablity distribution {.build}
- Probability **density** function (PDF)
  - Similar to a PMF, but instead specifies the probability that a *continuous* variable takes on a range of values.

\begin{columns}
\column{0.5\textwidth}
\centering
```{r pdf, echo=F, out.width='130%', out.height='90%'}
snd <- ggplot(data=data.frame('x'=c(-3,3)), aes(x)) + 
  stat_function(fun=dnorm, n=101, args = list(mean=0, sd=1)) + 
  labs(x='X', y=expression(paste(italic('p'), '(', italic('X'), ')'))) + 
  theme_classic()
snd
```

\column{0.5\textwidth}
\centering
\
\
\
Normal Distribution Notation\
\
$\textit{X}$ $\sim$ $\textit{N}(\mu,\sigma^2)$
\end{columns}

## Expected value and Variance {.build}
- The expected value of a random variable *Y* is denoted as *E*(*Y*).
  - Probability weighted average of all possible values.

```{r expectation, class.source="indent"}
y <- c(70,80,85,90,100)
p.y <- c(0.18,0.34,0.35,0.11,0.02)

E.y <- sum(y*p.y)
E.y 
```

- Variance
  - A measure of how disperse all possible values of a random variable are from the expected value (i.e. population or sample mean)

## Multivariate Distributions {.build}
### PDF $\rightarrow$ **Joint Probability Density**\
> - For the random variables *X* and *Y*, the joint pdf characterizes the probability that each *X* and *Y* takes on a set of values.

```{r joint_pdf, echo=F}
sigma <- matrix(c(1,0,0,1), ncol=2)
x <- mvrnorm(5000, c(0,0), sigma)
dens <- dmvnorm(x, mean=c(0,0), sigma=sigma)

#plot_ly(x=~x[,1], y=~x[,2], z=~dens, type='scatter3d', 
        #mode='markers',
        #marker=list(color = ~dens, colorscale = 'RdBu', showscale=F)) %>%
  
  #layout(scene=list(xaxis=list(title='X'), yaxis=list(title='Y'), 
                    #zaxis=list(title=list(text='p(X,Y)'))))

ggdraw() + draw_image('images/joint_pdf.jpeg', scale=1)
```

## Multivariate Distributions 
### Variance $\rightarrow$ **Covariance**\
>   - Measure of how much two random variables vary together.
> - Formally, is the expected value of each random variable's deviation from its respective expected value.
\
\
\centering
cov(*X*,*Y*) = *E*[(*X* - *E*[*X*])(*Y* - *E*[*Y*])]
\
\
> - Typically represented as a matrix.


## Marginal Distribution {.build}
- Probability distribution of an outcome for one random variable in the presence of all other outcomes for another random variable
```{r xy_table, echo=F}
xy_table <- matrix(c(4/32, 2/32, 1/32, 1/32,
                     3/32, 6/32, 3/32, 3/32,
                     9/32, 0, 0 , 0), ncol=4, byrow=T)

xy_table <- cbind(xy_table,rowSums(xy_table))
xy_table <- rbind(xy_table,c(colSums(xy_table[,c(1:4)]),1))

row.names(xy_table) <- c('y\\textsubscript{1}','y\\textsubscript{2}',
                         'y\\textsubscript{3}','p\\textsubscript{X}(x\\textsubscript{i})')

colnames(xy_table) <- c('x\\textsubscript{1}','x\\textsubscript{2}',
                        'x\\textsubscript{3}','x\\textsubscript{4}', 'p\\textsubscript{Y}(y\\textsubscript{i})')


xy_table[1:3,5] <- cell_spec(xy_table[0:3,5], color='red', bold=T, font_size = 12)
xy_table[4,1:4] <- cell_spec(xy_table[4,1:4], color='blue', bold=T, font_size = 12)

kbl(xy_table, digits=2, escape=F) %>% 
  kable_paper() %>% 
  row_spec(0, font_size = 11)  %>% 
  row_spec(1:4, font_size=11) 
  
```


## Pearson correlation & Statistical independence
- Pearson correlation coefficient $\rho$ measures the linear relationship between two random variables
\
- Two random variables are statistically independent if the realization of one does not affect the outcome of the other.

## Likelihood
> - Throughout this course we are going to use statistical models (e.g., regression, ANOVA) to describe patterns of variability in random variables.
> - These models have *parameters* (e.g., mean of a sampling distribution)
> - A **likelihood** function is the joint probability of observed data as a function of parameters in a statistical model. 

## {.build}
<div style='float: top; height: 50%;'>
\centering
```{r prob_dist_area, echo=F, out.height='50%'}
df.x <- data.frame(x=seq(-3,3,0.001))
df.x$d <- dnorm(df.x$x)

ggplot(data=df.x, aes(x,d)) + 
  geom_line() + 
  labs(x='x', y=expression(paste(italic('p'), '(', italic('X'), ')')), title='Probability') + 
  theme_classic() +
  geom_area(mapping=aes(x=ifelse(x > 1, x, 0)), fill='red', alpha=0.5) + 
  ylim(0,max(df.x$d)) + 
  annotate("text", x=1.51, y=dnorm(1)+0.04, 
           label=expression(paste('p(', italic(X),' > 1 | ', mu, '=0, ', sigma, '=1)',
                                  ' = 0.1587')), size = 6) + 
  theme(plot.title=element_text(hjust=0.5, size = 20))
```
</div>

<div style='float: bottom; height: 50%;'>
\centering
```{r likelihood, echo=F, out.height='50%'}
ggplot(data=df.x, aes(x,d)) + 
  geom_line() + 
  labs(x='x', y=expression(paste(italic('p'), '(', italic('X'), ')')), title='Likelihood') + 
  theme_classic() + 
  theme(plot.title=element_text(hjust=0.5, size = 20)) + 
  geom_segment(x=1, y=0, xend=1, yend=dnorm(1), 
               linetype='dashed', color='red', size=1.1) + 
  geom_point(mapping=(aes(x=1, y = dnorm(1))), size=8, shape=4, stroke=2, color='red') + 
  annotate("text",x=.905, y=dnorm(1)+.05, 
           label=expression(paste(italic('L'), '(', mu, '=0, ', sigma, '=1',
                                  '| ', italic('X'), '=1', ') = ',
                                  '0.2420')), size = 6)
```


# R

## Programming Tips
- Google is your best friend!
- More than a single way to skin a cat (code).
- Learn more than one language.
- Have fun!


